{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: **LoRA** - as suggested in the instructions\n",
    "* Model: **GPT-2** - as suggested in the instructions\n",
    "* Evaluation approach: **Huggingface Trainer: evaluate** - as suggested in the instructions\n",
    "* Fine-tuning dataset: **dair-ai/emotion** - Emotion is a dataset of English Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c553f351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.0 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc025228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          DataCollatorWithPadding, Trainer, \n",
    "                          TrainingArguments, AutoModelForSequenceClassification\n",
    "                         )\n",
    "from peft import (get_peft_config, get_peft_model, LoraConfig, \n",
    "                  TaskType, PeftModel, PeftConfig, \n",
    "                  AutoPeftModelForSequenceClassification\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f68079f05f42ccae4577d8e363d2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/9.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 1.03M/1.03M [00:00<00:00, 4.06MB/s]\n",
      "Downloading data: 100%|██████████| 127k/127k [00:00<00:00, 1.20MB/s]\n",
      "Downloading data: 100%|██████████| 129k/129k [00:00<00:00, 1.18MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95df8bc7e40d4cf4b8e265686eaa16ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb052ad5d504c10b248ff603273ebde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7ef0809aba4835a77707d75c9944a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 1500\n",
      "}) Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 100\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "splits = [\"train\", \"test\"]\n",
    "dataset = {split: ds for split, ds in zip(splits, load_dataset(\"dair-ai/emotion\", split=splits))}\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].shuffle(seed=42).select(range(1500))\n",
    "dataset[\"test\"] = dataset[\"test\"].shuffle(seed=42).select(range(100))\n",
    "    \n",
    "# View the dataset characteristics\n",
    "print(dataset[\"train\"], dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c866509a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 30, 1: 38, 2: 7, 3: 13, 4: 11, 5: 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(dataset[\"test\"][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593b47a8995a4697bad2413413a3fe2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b719b940589943fcb7cd2381dc030e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911db03d574c45228e7294ed776b0d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c053965b1f244991ab3c3dbff1cb2110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6074d4447be64dc0a93b0a5f5c375b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6be08e35e947be81c79ee4c905ebc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d897fa13cf004e9482bfdfc016892be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loading the gpt2 model from pre-trained\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Set the padding token to be the same as the end-of-sequence token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize_dataset(dataset, splits, tokenizer):\n",
    "    \"\"\"Tokenizes the dataset for the specified splits.\n",
    "\n",
    "    Args:\n",
    "        dataset: The dataset containing the splits.\n",
    "        splits: A list of split names (e.g., ['train', 'test']).\n",
    "        tokenizer: The tokenizer to use for tokenization.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing tokenized datasets for each split.\n",
    "    \"\"\"\n",
    "    tokenized_ds = {}\n",
    "    for split in splits:\n",
    "        tokenized_ds[split] = dataset[split].map(\n",
    "            lambda x: tokenizer(x['text'], padding='max_length', truncation=True, return_tensors='pt'),\n",
    "            batched=True\n",
    "        )\n",
    "    return tokenized_ds\n",
    "\n",
    "tokenized_dataset = tokenize_dataset(dataset, splits, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6a0307bbfb4ea093a3d624b1d22965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 6\n",
    "id2label = {\n",
    "            0: \"sadness\", \n",
    "            1: \"joy\",\n",
    "            2: \"love\",\n",
    "            3: \"anger\",\n",
    "            4: \"fear\",\n",
    "            5: \"surprise\"\n",
    "             }\n",
    "\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label, \n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "#freeze\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# set the pad token of the model's configuration\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=6, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2250' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2250/2250 07:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.210500</td>\n",
       "      <td>1.582065</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.510300</td>\n",
       "      <td>1.226986</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.218200</td>\n",
       "      <td>1.237575</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./data/emotion_analysis/checkpoint-750 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/emotion_analysis/checkpoint-1500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/emotion_analysis/checkpoint-2250 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2250, training_loss=1.610480740017361, metrics={'train_runtime': 464.2065, 'train_samples_per_second': 9.694, 'train_steps_per_second': 4.847, 'total_flos': 2351755689984000.0, 'train_loss': 1.610480740017361, 'epoch': 3.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/emotion_analysis\",\n",
    "        learning_rate=2e-3,\n",
    "        # Reduce the batch size if you don't have enough memory\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183740f0",
   "metadata": {},
   "source": [
    "### We then just evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d93b116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.226986289024353,\n",
       " 'eval_accuracy': 0.56,\n",
       " 'eval_runtime': 8.7776,\n",
       " 'eval_samples_per_second': 11.393,\n",
       " 'eval_steps_per_second': 5.696,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1779bcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i was feeling really troubled and down over wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel so thrilled to have three such distingu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  predicted_label\n",
       "0  i was feeling really troubled and down over wh...      0                4\n",
       "1  i feel so thrilled to have three such distingu...      1                1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(tokenized_dataset[\"test\"])\n",
    "df = df[[\"text\", \"label\"]]\n",
    "\n",
    "# Replace <br /> tags in the text with spaces\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"<br />\", \" \")\n",
    "\n",
    "# Add the model predictions to the dataframe\n",
    "predictions = trainer.predict(tokenized_dataset[\"test\"])\n",
    "df[\"predicted_label\"] = np.argmax(predictions[0], axis=1)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e1838bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_label\n",
       "1    50\n",
       "0    21\n",
       "3    15\n",
       "4    11\n",
       "2     3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"predicted_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bfcf058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i was feeling really troubled and down over wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>im feeling and if ive liked being pregnant</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i don t have the feeling of divine vibrations</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i vented my feelings towards the pathetic excu...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i get the feeling that this could be dangerous</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label  predicted_label\n",
       "0   i was feeling really troubled and down over wh...      0                4\n",
       "5          im feeling and if ive liked being pregnant      2                1\n",
       "8       i don t have the feeling of divine vibrations      1                4\n",
       "9   i vented my feelings towards the pathetic excu...      0                3\n",
       "11     i get the feeling that this could be dangerous      3                4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"label\"] != df[\"predicted_label\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f990c9",
   "metadata": {},
   "source": [
    "### PEFT Model - creating setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f80e6827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): ModulesToSaveWrapper(\n",
      "    (original_module): Linear(\n",
      "      in_features=768, out_features=6, bias=False\n",
      "      (lora_dropout): ModuleDict(\n",
      "        (default): Dropout(p=0.03, inplace=False)\n",
      "      )\n",
      "      (lora_A): ModuleDict(\n",
      "        (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "      )\n",
      "      (lora_B): ModuleDict(\n",
      "        (default): Linear(in_features=8, out_features=6, bias=False)\n",
      "      )\n",
      "      (lora_embedding_A): ParameterDict()\n",
      "      (lora_embedding_B): ParameterDict()\n",
      "    )\n",
      "    (modules_to_save): ModuleDict(\n",
      "      (default): Linear(\n",
      "        in_features=768, out_features=6, bias=False\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.03, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=8, out_features=6, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "transformer GPT2Model(\n",
      "  (wte): Embedding(50257, 768)\n",
      "  (wpe): Embedding(1024, 768)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (h): ModuleList(\n",
      "    (0-11): 12 x GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (act): NewGELUActivation()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "transformer.wte Embedding(50257, 768)\n",
      "transformer.wpe Embedding(1024, 768)\n",
      "transformer.drop Dropout(p=0.1, inplace=False)\n",
      "transformer.h ModuleList(\n",
      "  (0-11): 12 x GPT2Block(\n",
      "    (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): GPT2Attention(\n",
      "      (c_attn): Conv1D()\n",
      "      (c_proj): Conv1D()\n",
      "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): GPT2MLP(\n",
      "      (c_fc): Conv1D()\n",
      "      (c_proj): Conv1D()\n",
      "      (act): NewGELUActivation()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "transformer.h.0 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.0.ln_1 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.0.attn GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.0.attn.c_attn Conv1D()\n",
      "transformer.h.0.attn.c_proj Conv1D()\n",
      "transformer.h.0.attn.attn_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.0.attn.resid_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.0.ln_2 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.0.mlp GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.0.mlp.c_fc Conv1D()\n",
      "transformer.h.0.mlp.c_proj Conv1D()\n",
      "transformer.h.0.mlp.act NewGELUActivation()\n",
      "transformer.h.0.mlp.dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.1 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.1.ln_1 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.1.attn GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.1.attn.c_attn Conv1D()\n",
      "transformer.h.1.attn.c_proj Conv1D()\n",
      "transformer.h.1.attn.attn_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.1.attn.resid_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.1.ln_2 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.1.mlp GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.1.mlp.c_fc Conv1D()\n",
      "transformer.h.1.mlp.c_proj Conv1D()\n",
      "transformer.h.1.mlp.act NewGELUActivation()\n",
      "transformer.h.1.mlp.dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.2 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.2.ln_1 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.2.attn GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.2.attn.c_attn Conv1D()\n",
      "transformer.h.2.attn.c_proj Conv1D()\n",
      "transformer.h.2.attn.attn_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.2.attn.resid_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.2.ln_2 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.2.mlp GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.2.mlp.c_fc Conv1D()\n",
      "transformer.h.2.mlp.c_proj Conv1D()\n",
      "transformer.h.2.mlp.act NewGELUActivation()\n",
      "transformer.h.2.mlp.dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.3 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.3.ln_1 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.3.attn GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.3.attn.c_attn Conv1D()\n",
      "transformer.h.3.attn.c_proj Conv1D()\n",
      "transformer.h.3.attn.attn_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.3.attn.resid_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.3.ln_2 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.3.mlp GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.3.mlp.c_fc Conv1D()\n",
      "transformer.h.3.mlp.c_proj Conv1D()\n",
      "transformer.h.3.mlp.act NewGELUActivation()\n",
      "transformer.h.3.mlp.dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.4 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.4.ln_1 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.4.attn GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.4.attn.c_attn Conv1D()\n",
      "transformer.h.4.attn.c_proj Conv1D()\n",
      "transformer.h.4.attn.attn_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.4.attn.resid_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.4.ln_2 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.4.mlp GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.4.mlp.c_fc Conv1D()\n",
      "transformer.h.4.mlp.c_proj Conv1D()\n",
      "transformer.h.4.mlp.act NewGELUActivation()\n",
      "transformer.h.4.mlp.dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.5 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.5.ln_1 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.5.attn GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.5.attn.c_attn Conv1D()\n",
      "transformer.h.5.attn.c_proj Conv1D()\n",
      "transformer.h.5.attn.attn_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.5.attn.resid_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.5.ln_2 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.5.mlp GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.5.mlp.c_fc Conv1D()\n",
      "transformer.h.5.mlp.c_proj Conv1D()\n",
      "transformer.h.5.mlp.act NewGELUActivation()\n",
      "transformer.h.5.mlp.dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.6 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.6.ln_1 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.6.attn GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.6.attn.c_attn Conv1D()\n",
      "transformer.h.6.attn.c_proj Conv1D()\n",
      "transformer.h.6.attn.attn_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.6.attn.resid_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.6.ln_2 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.6.mlp GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.6.mlp.c_fc Conv1D()\n",
      "transformer.h.6.mlp.c_proj Conv1D()\n",
      "transformer.h.6.mlp.act NewGELUActivation()\n",
      "transformer.h.6.mlp.dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.7 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.7.ln_1 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.7.attn GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.7.attn.c_attn Conv1D()\n",
      "transformer.h.7.attn.c_proj Conv1D()\n",
      "transformer.h.7.attn.attn_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.7.attn.resid_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.7.ln_2 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.7.mlp GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.7.mlp.c_fc Conv1D()\n",
      "transformer.h.7.mlp.c_proj Conv1D()\n",
      "transformer.h.7.mlp.act NewGELUActivation()\n",
      "transformer.h.7.mlp.dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.8 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.8.ln_1 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.8.attn GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.8.attn.c_attn Conv1D()\n",
      "transformer.h.8.attn.c_proj Conv1D()\n",
      "transformer.h.8.attn.attn_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.8.attn.resid_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.8.ln_2 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.8.mlp GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.8.mlp.c_fc Conv1D()\n",
      "transformer.h.8.mlp.c_proj Conv1D()\n",
      "transformer.h.8.mlp.act NewGELUActivation()\n",
      "transformer.h.8.mlp.dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.9 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.9.ln_1 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.9.attn GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.9.attn.c_attn Conv1D()\n",
      "transformer.h.9.attn.c_proj Conv1D()\n",
      "transformer.h.9.attn.attn_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.9.attn.resid_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.9.ln_2 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.9.mlp GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.9.mlp.c_fc Conv1D()\n",
      "transformer.h.9.mlp.c_proj Conv1D()\n",
      "transformer.h.9.mlp.act NewGELUActivation()\n",
      "transformer.h.9.mlp.dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.10 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.10.ln_1 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.10.attn GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.10.attn.c_attn Conv1D()\n",
      "transformer.h.10.attn.c_proj Conv1D()\n",
      "transformer.h.10.attn.attn_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.10.attn.resid_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.10.ln_2 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.10.mlp GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.10.mlp.c_fc Conv1D()\n",
      "transformer.h.10.mlp.c_proj Conv1D()\n",
      "transformer.h.10.mlp.act NewGELUActivation()\n",
      "transformer.h.10.mlp.dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.11 GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.11.ln_1 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.11.attn GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.11.attn.c_attn Conv1D()\n",
      "transformer.h.11.attn.c_proj Conv1D()\n",
      "transformer.h.11.attn.attn_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.11.attn.resid_dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.h.11.ln_2 LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.11.mlp GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.11.mlp.c_fc Conv1D()\n",
      "transformer.h.11.mlp.c_proj Conv1D()\n",
      "transformer.h.11.mlp.act NewGELUActivation()\n",
      "transformer.h.11.mlp.dropout Dropout(p=0.1, inplace=False)\n",
      "transformer.ln_f LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "score ModulesToSaveWrapper(\n",
      "  (original_module): Linear(\n",
      "    in_features=768, out_features=6, bias=False\n",
      "    (lora_dropout): ModuleDict(\n",
      "      (default): Dropout(p=0.03, inplace=False)\n",
      "    )\n",
      "    (lora_A): ModuleDict(\n",
      "      (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "    )\n",
      "    (lora_B): ModuleDict(\n",
      "      (default): Linear(in_features=8, out_features=6, bias=False)\n",
      "    )\n",
      "    (lora_embedding_A): ParameterDict()\n",
      "    (lora_embedding_B): ParameterDict()\n",
      "  )\n",
      "  (modules_to_save): ModuleDict(\n",
      "    (default): Linear(\n",
      "      in_features=768, out_features=6, bias=False\n",
      "      (lora_dropout): ModuleDict(\n",
      "        (default): Dropout(p=0.03, inplace=False)\n",
      "      )\n",
      "      (lora_A): ModuleDict(\n",
      "        (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "      )\n",
      "      (lora_B): ModuleDict(\n",
      "        (default): Linear(in_features=8, out_features=6, bias=False)\n",
      "      )\n",
      "      (lora_embedding_A): ParameterDict()\n",
      "      (lora_embedding_B): ParameterDict()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "score.original_module Linear(\n",
      "  in_features=768, out_features=6, bias=False\n",
      "  (lora_dropout): ModuleDict(\n",
      "    (default): Dropout(p=0.03, inplace=False)\n",
      "  )\n",
      "  (lora_A): ModuleDict(\n",
      "    (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "  )\n",
      "  (lora_B): ModuleDict(\n",
      "    (default): Linear(in_features=8, out_features=6, bias=False)\n",
      "  )\n",
      "  (lora_embedding_A): ParameterDict()\n",
      "  (lora_embedding_B): ParameterDict()\n",
      ")\n",
      "score.original_module.lora_dropout ModuleDict(\n",
      "  (default): Dropout(p=0.03, inplace=False)\n",
      ")\n",
      "score.original_module.lora_dropout.default Dropout(p=0.03, inplace=False)\n",
      "score.original_module.lora_A ModuleDict(\n",
      "  (default): Linear(in_features=768, out_features=8, bias=False)\n",
      ")\n",
      "score.original_module.lora_A.default Linear(in_features=768, out_features=8, bias=False)\n",
      "score.original_module.lora_B ModuleDict(\n",
      "  (default): Linear(in_features=8, out_features=6, bias=False)\n",
      ")\n",
      "score.original_module.lora_B.default Linear(in_features=8, out_features=6, bias=False)\n",
      "score.original_module.lora_embedding_A ParameterDict()\n",
      "score.original_module.lora_embedding_B ParameterDict()\n",
      "score.modules_to_save ModuleDict(\n",
      "  (default): Linear(\n",
      "    in_features=768, out_features=6, bias=False\n",
      "    (lora_dropout): ModuleDict(\n",
      "      (default): Dropout(p=0.03, inplace=False)\n",
      "    )\n",
      "    (lora_A): ModuleDict(\n",
      "      (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "    )\n",
      "    (lora_B): ModuleDict(\n",
      "      (default): Linear(in_features=8, out_features=6, bias=False)\n",
      "    )\n",
      "    (lora_embedding_A): ParameterDict()\n",
      "    (lora_embedding_B): ParameterDict()\n",
      "  )\n",
      ")\n",
      "score.modules_to_save.default Linear(\n",
      "  in_features=768, out_features=6, bias=False\n",
      "  (lora_dropout): ModuleDict(\n",
      "    (default): Dropout(p=0.03, inplace=False)\n",
      "  )\n",
      "  (lora_A): ModuleDict(\n",
      "    (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "  )\n",
      "  (lora_B): ModuleDict(\n",
      "    (default): Linear(in_features=8, out_features=6, bias=False)\n",
      "  )\n",
      "  (lora_embedding_A): ParameterDict()\n",
      "  (lora_embedding_B): ParameterDict()\n",
      ")\n",
      "score.modules_to_save.default.lora_dropout ModuleDict(\n",
      "  (default): Dropout(p=0.03, inplace=False)\n",
      ")\n",
      "score.modules_to_save.default.lora_dropout.default Dropout(p=0.03, inplace=False)\n",
      "score.modules_to_save.default.lora_A ModuleDict(\n",
      "  (default): Linear(in_features=768, out_features=8, bias=False)\n",
      ")\n",
      "score.modules_to_save.default.lora_A.default Linear(in_features=768, out_features=8, bias=False)\n",
      "score.modules_to_save.default.lora_B ModuleDict(\n",
      "  (default): Linear(in_features=8, out_features=6, bias=False)\n",
      ")\n",
      "score.modules_to_save.default.lora_B.default Linear(in_features=8, out_features=6, bias=False)\n",
      "score.modules_to_save.default.lora_embedding_A ParameterDict()\n",
      "score.modules_to_save.default.lora_embedding_B ParameterDict()\n"
     ]
    }
   ],
   "source": [
    "# Access the encoder layers (if applicable)\n",
    "for name, layer in model.named_modules():\n",
    "    print(name, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 304,128 || all params: 124,743,936 || trainable%: 0.2438018309763771\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Need to setup the configuration using LoraCongif\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS, \n",
    "    inference_mode=False, \n",
    "    r=8, \n",
    "    target_modules=[\"c_attn\"],\n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.03\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",    \n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label, \n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "# creating a PEFT model\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model.print_trainable_parameters()\n",
    "\n",
    "peft_model.config.pad_token_id = peft_model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7a5b76",
   "metadata": {},
   "source": [
    "### We apply similar logic as above. Functions were already created for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa7fe003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 03:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.641300</td>\n",
       "      <td>2.450142</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=750, training_loss=4.518879069010417, metrics={'train_runtime': 218.6191, 'train_samples_per_second': 6.861, 'train_steps_per_second': 3.431, 'total_flos': 786678939648000.0, 'train_loss': 4.518879069010417, 'epoch': 1.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:126'  # Adjust the size as needed\n",
    "#torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/emotion_analysis_perf\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.02,\n",
    "        load_best_model_at_end=True,\n",
    "        fp16=True\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e5e1e0",
   "metadata": {},
   "source": [
    "### Evaluation of PEFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e51e9290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.450141668319702,\n",
       " 'eval_accuracy': 0.25,\n",
       " 'eval_runtime': 5.4425,\n",
       " 'eval_samples_per_second': 18.374,\n",
       " 'eval_steps_per_second': 9.187,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cd30d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predictions</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  predictions  labels\n",
       "0          3            0       3\n",
       "1          4            0       4\n",
       "2          0            0       0\n",
       "3          3            0       3\n",
       "4          1            3       1\n",
       "5          0            0       0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_for_manual_review = tokenized_dataset[\"test\"].select(\n",
    "    [34, 57, 99, 25, 44, 89]\n",
    ")\n",
    "\n",
    "results = trainer.predict(items_for_manual_review)\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"sentiment\": [item[\"label\"] for item in items_for_manual_review],\n",
    "        \"predictions\": results.predictions.argmax(axis=1),\n",
    "        \"labels\": results.label_ids,\n",
    "    }\n",
    ")\n",
    "# Show all the cell\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db09766",
   "metadata": {},
   "source": [
    "### Finally saving the PEFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f609317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the trained model\n",
    "peft_model.save_pretrained(\"./peft_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec2f83",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_saved = \"./peft_model\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2ForSequenceClassification(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): Linear(\n",
       "                in_features=768, out_features=2304, bias=True\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.03, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=6, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=6, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_peft_inf = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "        peft_saved,\n",
    "        num_labels=num_labels,\n",
    "        id2label=id2label, \n",
    "        label2id=label2id)\n",
    "\n",
    "model_peft_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "568a672d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(peft_type='LORA', auto_mapping=None, base_model_name_or_path='gpt2', revision=None, task_type='SEQ_CLS', inference_mode=True, r=8, target_modules=['c_attn'], lora_alpha=32, lora_dropout=0.03, fan_in_fan_out=True, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None)\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "inference_dataset = tokenized_dataset[\"test\"].select(\n",
    "    [random.randint(0, 100) for _ in range(10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6afb7019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 10\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(inference_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef869833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i just notice what i am doing that is ruining my happy moment because this feelingof discontent is my resistance to receiving love in the genuine way its being delivered\n",
      "i am off on wednesday to a postgraduate open day but there will be plenty to write about the rest of the week i feel sure\n",
      "i feel very glad that finland s well known visual artist vesa kivinen had called me to work with him\n",
      "i get the feeling that this could be dangerous\n",
      "i feel special excitement and happiness\n",
      "is hand started fondling his aching cock through the fabric of his boxers and he instinctively arched his back to feel more of the delicious sensation\n",
      "i sit here writing this i feel unhappy inside\n",
      "i tune out the rest of the world and focus on the rhythm of the needles and the softness of the yarn and for that time i feel my most peaceful\n",
      "i get the feeling that this could be dangerous\n",
      "i don t care if any of you read this but this is just what i feel when i m around you guys i feel hated\n"
     ]
    }
   ],
   "source": [
    "for x in inference_dataset:\n",
    "    print(x[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(inference_dataset, model_peft_inf):\n",
    "    \n",
    "    #Go through each sample of inference\n",
    "    tokenized_inference_dataset = inference_dataset.map(lambda x: tokenizer(x['text'], padding='max_length', truncation=True, return_tensors='pt'))\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "   \n",
    "    predicted_labels = []\n",
    "    predicted_class_indexes = []\n",
    "    for x in inference_dataset:\n",
    " \n",
    "        # set to evaluation mode\n",
    "        model_peft_inf.eval()\n",
    "        \n",
    "        # Perform inference\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "            outputs = model_peft_inf(**inputs)\n",
    "\n",
    "        # Get the logits (raw predictions)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Apply softmax to get probabilities\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "        # Get the predicted class (index of the maximum probability)\n",
    "        predicted_class_index = torch.argmax(probabilities, dim=-1).item()\n",
    "\n",
    "        # Map the predicted class index to the corresponding label\n",
    "        predicted_label = id2label[predicted_class_index]\n",
    "        \n",
    "        #Append\n",
    "        predicted_labels.append(predicted_label)\n",
    "        predicted_class_indexes.append(predicted_class_index)\n",
    "    \n",
    "    df_inf = pd.DataFrame(\n",
    "    {\n",
    "        \"text\": [x[\"text\"] for x in inference_dataset],\n",
    "        \"predicted_label\": predicted_labels,\n",
    "        \"predicted_label_num\": predicted_class_indexes,\n",
    "        \"actual_labels\": [x[\"label\"] for x in inference_dataset],\n",
    "    }\n",
    ")\n",
    "# Show all the cell\n",
    "\n",
    "    return df_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inf = inference(inference_dataset=inference_dataset, \n",
    "          model_peft_inf=model_peft_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6b5f6eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_label_num</th>\n",
       "      <th>actual_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i just notice what i am doing that is ruining my happy moment because this feelingof discontent is my resistance to receiving love in the genuine way its being delivered</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am off on wednesday to a postgraduate open day but there will be plenty to write about the rest of the week i feel sure</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel very glad that finland s well known visual artist vesa kivinen had called me to work with him</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i get the feeling that this could be dangerous</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel special excitement and happiness</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                        text  \\\n",
       "0  i just notice what i am doing that is ruining my happy moment because this feelingof discontent is my resistance to receiving love in the genuine way its being delivered   \n",
       "1                                                  i am off on wednesday to a postgraduate open day but there will be plenty to write about the rest of the week i feel sure   \n",
       "2                                                                       i feel very glad that finland s well known visual artist vesa kivinen had called me to work with him   \n",
       "3                                                                                                                             i get the feeling that this could be dangerous   \n",
       "4                                                                                                                                    i feel special excitement and happiness   \n",
       "\n",
       "  predicted_label  predicted_label_num  actual_labels  \n",
       "0           anger                    3              0  \n",
       "1           anger                    3              1  \n",
       "2           anger                    3              1  \n",
       "3           anger                    3              3  \n",
       "4           anger                    3              1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cde634",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6a009aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00         5\n",
      "           3       0.20      1.00      0.33         2\n",
      "\n",
      "    accuracy                           0.20        10\n",
      "   macro avg       0.07      0.33      0.11        10\n",
      "weighted avg       0.04      0.20      0.07        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "true_labels = list(df_inf['actual_labels'].values)\n",
    "predicted_labels = list(df_inf['predicted_label_num'].values)\n",
    "\n",
    "print(classification_report(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e89490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
